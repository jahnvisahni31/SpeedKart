{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6258fe2a1fee46ee909379a6cceff36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "jpeg",
            "height": "480",
            "layout": "IPY_MODEL_5c6fb4709fe0464f89212311fd5ee6d3",
            "width": "640"
          }
        },
        "5c6fb4709fe0464f89212311fd5ee6d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01d5916f89544b9a98b05f4f7b6da0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "jpeg",
            "height": "480",
            "layout": "IPY_MODEL_ec36fe766b4045818cd3026de6cd568d",
            "width": "640"
          }
        },
        "ec36fe766b4045818cd3026de6cd568d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LanFZu-eBvdN"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python torch torchvision ultralytics ipywidgets pillow GitPython --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video streaming image detection"
      ],
      "metadata": {
        "id": "5rggO4zMfrGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "import io\n",
        "from PIL import Image as PILImage\n",
        "import ipywidgets as widgets\n",
        "import time"
      ],
      "metadata": {
        "id": "_Y5jbDjYZUHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Capture';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element.\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            // Wait for Capture to be clicked.\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename\n",
        "\n",
        "# Take a photo\n",
        "image_file = take_photo()\n",
        "\n",
        "# Read and display the image\n",
        "image = cv2.imread(image_file)\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "collapsed": true,
        "id": "UNm7rv80ZY2p",
        "outputId": "e3c43182-438a-41d0-e4f1-48a45651437d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const capture = document.createElement('button');\n",
              "            capture.textContent = 'Capture';\n",
              "            div.appendChild(capture);\n",
              "\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            // Resize the output to fit the video element.\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            // Wait for Capture to be clicked.\n",
              "            await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-cdcec361d396>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Take a photo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mimage_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Read and display the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-cdcec361d396>\u001b[0m in \u001b[0;36mtake_photo\u001b[0;34m(filename, quality)\u001b[0m\n\u001b[1;32m     36\u001b[0m     ''')\n\u001b[1;32m     37\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'takePhoto({})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the YOLO model\n",
        "model = YOLO('yolov5s.pt')  # Load the smallest YOLOv5 model"
      ],
      "metadata": {
        "id": "SrCHU_okZdiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537dd0d8-c2cd-4e74-d467-f3dfd815f1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRO TIP ðŸ’¡ Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov5su.pt to 'yolov5su.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.7M/17.7M [00:00<00:00, 367MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming we've already taken a photo using the previous code\n",
        "image_file = 'test_1.jpeg'\n",
        "\n",
        "# Read the image\n",
        "image = cv2.imread(image_file)\n",
        "\n",
        "# Perform object detection\n",
        "results = model(image)\n",
        "\n",
        "# Process the results\n",
        "for result in results:\n",
        "    boxes = result.boxes.xyxy.cpu().numpy().astype(int)\n",
        "    classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "    confidences = result.boxes.conf.cpu().numpy()\n",
        "\n",
        "    # Draw bounding boxes and labels on the image\n",
        "    for box, cls, conf in zip(boxes, classes, confidences):\n",
        "        x1, y1, x2, y2 = box\n",
        "        label = f'{model.names[cls]} {conf:.2f}'\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "# Display the image with detections\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jCq_77YFZ8p6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "21bfee77-e237-44d1-f839-6b5c735e8efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ 'source' is missing. Using 'source=/usr/local/lib/python3.10/dist-packages/ultralytics/assets'.\n",
            "\n",
            "image 1/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/bus.jpg: 640x480 4 persons, 1 bus, 734.0ms\n",
            "image 2/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/zidane.jpg: 384x640 2 persons, 2 ties, 511.6ms\n",
            "Speed: 10.7ms preprocess, 622.8ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'clip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c81bd119bd22>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Display the image with detections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0man\u001b[0m \u001b[0mNxM\u001b[0m \u001b[0mBGRA\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the YOLO model\n",
        "model = YOLO('yolov5s.pt')\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    return PILImage.open(io.BytesIO(binary))\n",
        "\n",
        "def process_image(image):\n",
        "    # Convert PIL Image to OpenCV format\n",
        "    open_cv_image = np.array(image)\n",
        "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
        "\n",
        "    # Perform object detection\n",
        "    results = model(open_cv_image)\n",
        "\n",
        "    # Process the results\n",
        "    for result in results:\n",
        "        boxes = result.boxes.xyxy.cpu().numpy().astype(int)\n",
        "        classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "        confidences = result.boxes.conf.cpu().numpy()\n",
        "\n",
        "        # Draw bounding boxes and labels on the image\n",
        "        for box, cls, conf in zip(boxes, classes, confidences):\n",
        "            x1, y1, x2, y2 = box\n",
        "            label = f'{model.names[cls]} {conf:.2f}'\n",
        "            cv2.rectangle(open_cv_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(open_cv_image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    return PILImage.fromarray(open_cv_image[:, :, ::-1])\n",
        "\n",
        "# Create a widget to display the video stream\n",
        "image_widget = widgets.Image(format='jpeg', width=640, height=480)\n",
        "display(image_widget)\n",
        "\n",
        "# Main loop for continuous capture and detection\n",
        "try:\n",
        "    while True:\n",
        "        # Capture frame\n",
        "        frame = take_photo()\n",
        "\n",
        "        # Process frame\n",
        "        processed_frame = process_image(frame)\n",
        "\n",
        "        # Convert PIL Image to JPEG bytes\n",
        "        img_byte_arr = io.BytesIO()\n",
        "        processed_frame.save(img_byte_arr, format='JPEG')\n",
        "        img_byte_arr = img_byte_arr.getvalue()\n",
        "\n",
        "        # Update widget with new frame\n",
        "        image_widget.value = img_byte_arr\n",
        "\n",
        "        # Add a small delay to control the frame rate\n",
        "        time.sleep(0.1)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopped\")"
      ],
      "metadata": {
        "id": "MFANueNcabx7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6258fe2a1fee46ee909379a6cceff36f",
            "5c6fb4709fe0464f89212311fd5ee6d3"
          ]
        },
        "outputId": "c8079e0d-04c4-4b36-d8ce-e45f87e8117e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRO TIP ðŸ’¡ Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Image(value=b'', format='jpeg', height='480', width='640')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6258fe2a1fee46ee909379a6cceff36f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 616.1ms\n",
            "Speed: 8.3ms preprocess, 616.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 402.7ms\n",
            "Speed: 6.1ms preprocess, 402.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 438.3ms\n",
            "Speed: 7.0ms preprocess, 438.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 425.6ms\n",
            "Speed: 7.1ms preprocess, 425.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 2 persons, 395.6ms\n",
            "Speed: 6.3ms preprocess, 395.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 toothbrush, 387.5ms\n",
            "Speed: 5.6ms preprocess, 387.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 remote, 519.1ms\n",
            "Speed: 5.4ms preprocess, 519.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 397.2ms\n",
            "Speed: 6.6ms preprocess, 397.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 cell phone, 405.2ms\n",
            "Speed: 5.8ms preprocess, 405.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 hot dog, 1 donut, 1 cell phone, 435.3ms\n",
            "Speed: 6.3ms preprocess, 435.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 remote, 1 cell phone, 424.0ms\n",
            "Speed: 6.6ms preprocess, 424.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 cell phone, 615.3ms\n",
            "Speed: 10.1ms preprocess, 615.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 cell phone, 433.9ms\n",
            "Speed: 6.7ms preprocess, 433.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 417.4ms\n",
            "Speed: 6.4ms preprocess, 417.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 455.4ms\n",
            "Speed: 8.9ms preprocess, 455.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 toothbrush, 423.0ms\n",
            "Speed: 5.8ms preprocess, 423.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Motion detection"
      ],
      "metadata": {
        "id": "Z8RKncIIghR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the YOLO model\n",
        "try:\n",
        "    model = YOLO('yolov8s.pt')\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Dictionary to store previous positions of objects\n",
        "prev_positions = {}\n",
        "\n",
        "def take_photo(filename='test_1.jpeg', quality=0.8):\n",
        "    try:\n",
        "        js = Javascript('''\n",
        "            async function takePhoto(quality) {\n",
        "                const div = document.createElement('div');\n",
        "                const video = document.createElement('video');\n",
        "                video.style.display = 'block';\n",
        "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "                document.body.appendChild(div);\n",
        "                div.appendChild(video);\n",
        "                video.srcObject = stream;\n",
        "                await video.play();\n",
        "                const canvas = document.createElement('canvas');\n",
        "                canvas.width = video.videoWidth;\n",
        "                canvas.height = video.videoHeight;\n",
        "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "                stream.getVideoTracks()[0].stop();\n",
        "                div.remove();\n",
        "                return canvas.toDataURL('image/jpeg', quality);\n",
        "            }\n",
        "        ''')\n",
        "        display(js)\n",
        "        data = eval_js('takePhoto({})'.format(quality))\n",
        "        binary = b64decode(data.split(',')[1])\n",
        "        return PILImage.open(io.BytesIO(binary))\n",
        "    except Exception as e:\n",
        "        print(f\"Error taking photo: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_image(image):\n",
        "    global prev_positions\n",
        "\n",
        "    # Convert PIL Image to OpenCV format\n",
        "    open_cv_image = np.array(image)\n",
        "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
        "\n",
        "    # Perform object detection\n",
        "    try:\n",
        "        results = model(open_cv_image)\n",
        "    except Exception as e:\n",
        "        print(f\"Error performing object detection: {e}\")\n",
        "        return image\n",
        "\n",
        "    # Process the results\n",
        "    for result in results:\n",
        "        boxes = result.boxes.xyxy.cpu().numpy().astype(int)\n",
        "        classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "        confidences = result.boxes.conf.cpu().numpy()\n",
        "\n",
        "        # Draw bounding boxes and labels on the image\n",
        "        for box, cls, conf in zip(boxes, classes, confidences):\n",
        "            x1, y1, x2, y2 = box\n",
        "            center_y = (y1 + y2) / 2\n",
        "            label = f'{model.names[cls]} {conf:.2f}'\n",
        "\n",
        "            # Check for vertical motion\n",
        "            if cls in prev_positions:\n",
        "                prev_y = prev_positions[cls]\n",
        "                if center_y < prev_y - 5:  # Object moved up\n",
        "                    label += ' UP'\n",
        "                elif center_y > prev_y + 5:  # Object moved down\n",
        "                    label += ' DOWN'\n",
        "\n",
        "            # Update position\n",
        "            prev_positions[cls] = center_y\n",
        "\n",
        "            cv2.rectangle(open_cv_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(open_cv_image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    return PILImage.fromarray(open_cv_image[:, :, ::-1])\n",
        "\n",
        "# Create a widget to display the video stream\n",
        "image_widget = widgets.Image(format='jpeg', width=640, height=480)\n",
        "display(image_widget)\n",
        "\n",
        "# Main loop for continuous capture and detection\n",
        "try:\n",
        "    while True:\n",
        "        # Capture frame\n",
        "        frame = take_photo()\n",
        "        if frame is None:\n",
        "            continue\n",
        "\n",
        "        # Process frame\n",
        "        processed_frame = process_image(frame)\n",
        "\n",
        "        # Convert PIL Image to JPEG bytes\n",
        "        img_byte_arr = io.BytesIO()\n",
        "        processed_frame.save(img_byte_arr, format='JPEG')\n",
        "        img_byte_arr = img_byte_arr.getvalue()\n",
        "\n",
        "        # Update widget with new frame\n",
        "        image_widget.value = img_byte_arr\n",
        "\n",
        "        # Add a small delay to control the frame rate\n",
        "        time.sleep(0.1)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopped\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a01d5916f89544b9a98b05f4f7b6da0f",
            "ec36fe766b4045818cd3026de6cd568d"
          ]
        },
        "id": "8J2OWx-xfT1R",
        "outputId": "0d9e3226-33cd-4b8b-dc2f-b4f1edd26f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Image(value=b'', format='jpeg', height='480', width='640')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a01d5916f89544b9a98b05f4f7b6da0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 504.9ms\n",
            "Speed: 6.9ms preprocess, 504.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 475.9ms\n",
            "Speed: 3.8ms preprocess, 475.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 2 persons, 448.9ms\n",
            "Speed: 4.2ms preprocess, 448.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 693.2ms\n",
            "Speed: 3.6ms preprocess, 693.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 527.1ms\n",
            "Speed: 6.1ms preprocess, 527.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 491.0ms\n",
            "Speed: 4.9ms preprocess, 491.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 436.5ms\n",
            "Speed: 3.3ms preprocess, 436.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 441.4ms\n",
            "Speed: 4.3ms preprocess, 441.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 (no detections), 764.2ms\n",
            "Speed: 6.6ms preprocess, 764.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 (no detections), 432.2ms\n",
            "Speed: 4.1ms preprocess, 432.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 (no detections), 477.3ms\n",
            "Speed: 4.6ms preprocess, 477.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 (no detections), 494.9ms\n",
            "Speed: 3.4ms preprocess, 494.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 2 persons, 1 remote, 449.1ms\n",
            "Speed: 3.0ms preprocess, 449.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 745.3ms\n",
            "Speed: 4.8ms preprocess, 745.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 437.9ms\n",
            "Speed: 3.8ms preprocess, 437.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 cell phone, 465.1ms\n",
            "Speed: 4.1ms preprocess, 465.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 2 persons, 1 cell phone, 503.7ms\n",
            "Speed: 5.4ms preprocess, 503.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 cell phone, 634.0ms\n",
            "Speed: 3.8ms preprocess, 634.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 2 cell phones, 494.7ms\n",
            "Speed: 7.5ms preprocess, 494.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 cell phone, 433.5ms\n",
            "Speed: 3.6ms preprocess, 433.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 2 persons, 1 laptop, 1 cell phone, 451.1ms\n",
            "Speed: 5.1ms preprocess, 451.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 2 persons, 1 cell phone, 511.7ms\n",
            "Speed: 4.7ms preprocess, 511.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 cell phone, 741.7ms\n",
            "Speed: 3.4ms preprocess, 741.7ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 2 persons, 1 cell phone, 496.8ms\n",
            "Speed: 4.1ms preprocess, 496.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 469.2ms\n",
            "Speed: 2.9ms preprocess, 469.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 cell phone, 447.0ms\n",
            "Speed: 2.7ms preprocess, 447.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 traffic light, 467.7ms\n",
            "Speed: 3.5ms preprocess, 467.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 1 traffic light, 776.6ms\n",
            "Speed: 7.1ms preprocess, 776.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 (no detections), 470.2ms\n",
            "Speed: 3.6ms preprocess, 470.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 440.3ms\n",
            "Speed: 3.4ms preprocess, 440.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 1 person, 429.1ms\n",
            "Speed: 4.7ms preprocess, 429.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            async function takePhoto(quality) {\n",
              "                const div = document.createElement('div');\n",
              "                const video = document.createElement('video');\n",
              "                video.style.display = 'block';\n",
              "                const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "                document.body.appendChild(div);\n",
              "                div.appendChild(video);\n",
              "                video.srcObject = stream;\n",
              "                await video.play();\n",
              "                const canvas = document.createElement('canvas');\n",
              "                canvas.width = video.videoWidth;\n",
              "                canvas.height = video.videoHeight;\n",
              "                canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "                stream.getVideoTracks()[0].stop();\n",
              "                div.remove();\n",
              "                return canvas.toDataURL('image/jpeg', quality);\n",
              "            }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVVxMLKegkec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}